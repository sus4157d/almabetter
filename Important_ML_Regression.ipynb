{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1MFy-IhO76ClGayZK3IGiS8GkvBKd4xJQ",
      "authorship_tag": "ABX9TyPhpBX9l0l37oW7Sf5tgX7X",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sus4157d/almabetter/blob/main/Important_ML_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from numpy import math\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import statsmodels.api as sm\n",
        "import statsmodels.formula.api as smf\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from scipy.stats import zscore\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from datetime import date\n",
        "from datetime import datetime"
      ],
      "metadata": {
        "id": "JIjVHye5W-ph"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eOkviqWIcyr7"
      },
      "outputs": [],
      "source": [
        "df=pd.read_csv(\"/content/drive/MyDrive/bike_sharing/SeoulBikeData.csv\",encoding = \"ISO-8859-1\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import date\n",
        "from datetime import datetime"
      ],
      "metadata": {
        "id": "F6XaYjyzzbP-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_cardekho.drop_duplicates(keep='first', inplace=True)"
      ],
      "metadata": {
        "id": "aw-9VAn02QQM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# converting date to week no.\n",
        "df['Date']=pd.to_datetime(df['Date'])\n",
        "df['Week_number'] = df['Date'].dt.isocalendar().week\n",
        "df['date_month']=df['Date'].dt.isocalendar.date\n",
        "df['day_week']=df['Date'].dt.weekday"
      ],
      "metadata": {
        "id": "JuEGSYJKY5_3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(df[df.duplicated()])"
      ],
      "metadata": {
        "id": "XBFfm2MFZO-y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfn['company_cat']=dfn['mean_price'].apply(lambda x: 0 if x < 3.136715e+05 else (1 if x<5.044551e+05 else 2))"
      ],
      "metadata": {
        "id": "XuZllxkxZrX6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfn=dfn.merge(dftemp,on=\"company\",how=\"left\")"
      ],
      "metadata": {
        "id": "yqhCGYhRZvDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfn.drop(index=index_d,inplace=True)"
      ],
      "metadata": {
        "id": "4gaE24WDZ37G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(7,4))\n",
        "sns.distplot(dfn[\"selling_price\"])"
      ],
      "metadata": {
        "id": "kCzwRYq0dSIz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfn.drop_duplicates(inplace=True)"
      ],
      "metadata": {
        "id": "Tug9-5d0dVKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import FunctionTransformer\n",
        "transformer = FunctionTransformer(np.log1p)\n",
        "transformer.transform(X)"
      ],
      "metadata": {
        "id": "gpMGQKR9LxZD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below are the some type of method or way to deal above type of problem.\n",
        "\n",
        "square-root for moderate skew: sqrt(x) for positively skewed data, sqrt(max(x+1) - x) for negatively skewed data\n",
        "\n",
        "log for greater skew: log10(x) for positively skewed data, log10(max(x+1) - x) for negatively skewed data\n",
        "\n",
        "inverse for severe skew: 1/x for positively skewed data 1/(max(x+1) - x) for negatively skewed data\n",
        "\n",
        "Linearity and heteroscedasticity: First try log transformation in a situation where the dependent variable starts to increase more rapidly with increasing independent variable values If your data does the opposite – dependent variable values decrease more rapidly with increasing independent variable values – you can first consider a square transformation."
      ],
      "metadata": {
        "id": "y34Bh3vXk1vJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Pv1bBbmUk31t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for col in numeric_features:\n",
        "    fig = plt.figure(figsize=(9, 6))\n",
        "    ax = fig.gca()\n",
        "    feature = df_cardekho[col]\n",
        "    feature.hist(bins=50, ax = ax)\n",
        "    ax.axvline(feature.mean(), color='magenta', linestyle='dashed', linewidth=2)\n",
        "    ax.axvline(feature.median(), color='cyan', linestyle='dashed', linewidth=2)\n",
        "    ax.set_title(col)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "uslr_gA6o7fu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8,5))\n",
        "sns.regplot(x='Car Age',y='selling_price',data=df_cardekho,color='red')"
      ],
      "metadata": {
        "id": "XWvorA4cxNJi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_vif(X):\n",
        "\n",
        "   # Calculating VIF\n",
        "   vif = pd.DataFrame()\n",
        "   vif[\"variables\"] = X.columns\n",
        "   vif[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
        "\n",
        "   return(vif)"
      ],
      "metadata": {
        "id": "aFSgwBOF1ILJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calc_vif(df_cardekho[[i for i in df_cardekho.describe().columns if i not in ['year','selling_price']]])"
      ],
      "metadata": {
        "id": "X189-vxPxN7b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature.extend(['Funct_day_No', 'Funct_day_Yes', 'Holiday_Holiday',\n",
        "       'Holiday_No Holiday'])"
      ],
      "metadata": {
        "id": "RIlTVW9HOL00"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfc=pd.get_dummies(dfc,columns=[\"Funct_day\",\"Holiday\"],prefix=[\"Funct_day\",\"Holiday\"])"
      ],
      "metadata": {
        "id": "0fj2kO4UOLxX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_num={'Seasons':{'Autumn':0,'Winter':1,'Spring':2,'Summer':3}}\n",
        "dfc=dfc.replace(encoder_num)"
      ],
      "metadata": {
        "id": "XmxZRrTWOLt7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for col in cat_f:\n",
        "  fig=plt.figure(figsize=(8,5))\n",
        "  ax=fig.gca()\n",
        "  df.boxplot(column=\"Rent_bike_count\",by=col,ax=ax)\n",
        "  ax.set_title(\"label by \"+col)\n",
        "  ax.set_title(\"Bike_count\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0KLafRkXOLra"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for col in cat_f:\n",
        "  counts=df[col].value_counts().sort_index()\n",
        "  fig=plt.figure(figsize=(8,5))\n",
        "  ax=fig.gca()\n",
        "  counts.plot.bar(ax=ax,color='red')\n",
        "  plt.title(col + \" counts \")\n",
        "  plt.xlabel(col)\n",
        "  plt.ylabel(\"freq\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dZ6S5SSqOLnf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=df[df[\"Rent_bike_count\"]>0]"
      ],
      "metadata": {
        "id": "6eKl5sGNUpf7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here are three common evaluation metrics for regression problems:\n",
        "\n",
        "Mean Absolute Error (MAE) is the mean of the absolute value of the errors:\n",
        "\n",
        "1n∑i=1n|yi−y^i|\n",
        "\n",
        "Mean Squared Error (MSE) is the mean of the squared errors:\n",
        "\n",
        "1n∑i=1n(yi−y^i)2\n",
        "\n",
        "Root Mean Squared Error (RMSE) bold text is the square root of the mean of the squared errors:\n",
        "\n",
        "1n∑i=√1n(yi−y^i)2\n",
        "\n",
        "Comparing these metrics:\n",
        "\n",
        "MAE is the easiest to understand, because it's the average error.\n",
        "MSE is more popular than MAE, because MSE \"punishes\" larger errors, which tends to be useful in the real world.\n",
        "RMSE is even more popular than MSE, because RMSE is interpretable in the \"y\" units.\n",
        "All of these are loss functions, because we want to minimize them."
      ],
      "metadata": {
        "id": "M2iIXKtMPi99"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "def eval_metric(y_test,y_pred):\n",
        "  MSE  = mean_squared_error((y_test), (y_pred))\n",
        "  print(\"MSE :\" , MSE)\n",
        "\n",
        "  MAE=mean_absolute_error((y_test), (y_pred))\n",
        "  print(\"MAE :\" ,MAE)\n",
        "\n",
        "  RMSE = np.sqrt(MSE)\n",
        "  print(\"RMSE :\" ,RMSE)\n",
        "\n",
        "  r2 = r2_score((y_test), (y_pred))\n",
        "  print(\"R2 :\" ,r2)\n",
        "  print(\"Adjusted R2 : \",1-(1-r2_score((y_test), (y_pred)))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)))"
      ],
      "metadata": {
        "id": "djsOZkCqXGCs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#feature.extend(['Funct_day_No', 'Funct_day_Yes', 'Holiday_Holiday',\n",
        " #      'Holiday_No Holiday','Seasons_Autumn',\t'Seasons_Spring',\t'Seasons_Summer',\t'Seasons_Winter'])"
      ],
      "metadata": {
        "id": "SfZDu5XUOLjp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dfc=pd.get_dummies(dfc,columns=[\"Funct_day\",\"Holiday\",\"Seasons\"],prefix=[\"Funct_day\",\"Holiday\",\"Seasons\"])"
      ],
      "metadata": {
        "id": "nvDXzEquOLef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "[[3745  388]\n",
        " [ 819  682]]"
      ],
      "metadata": {
        "id": "5sLW7PPvOLaV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "accuracy - How accurate i am . i predicated churn and it actually churned plus i predicated not churn and it acutally didnt churn.\n",
        "divided by total no of all the cases.3745+682/3745+388+819+682\n"
      ],
      "metadata": {
        "id": "eD9FjDxR4Ypu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "precision=how precise i am in prediciton. i predicted churn and actually churned divided by sum of predicted churn and actually churn plus predicted churn and didnot churn 682/682+388"
      ],
      "metadata": {
        "id": "dqEQJ5c55O_g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "recall-how much i am able to recall. i predicted churn and actuall churned divided by sum of acutally churned (predicted churn and actually churn plus prdicated not churne and actuall churn 682/682+819"
      ],
      "metadata": {
        "id": "nUL7QI5g7WhB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "insurance_df = insurance_df.dropna(thresh=insurance_df.shape[0]*0.4,axis=1)\n",
        "#droping column with more than 40 per of na value"
      ],
      "metadata": {
        "id": "PINLGxkeNhSQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#impoptant lybrary\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from datetime import datetime\n",
        "#machine learning\n",
        "import xgboost as xgb\n",
        "from xgboost import XGBClassifier\n",
        "#for hyperparameter tunning and cross velidation\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from sklearn.model_selection import RandomizedSearchCV , GridSearchCV\n",
        "#lyb for evaluation of model\n",
        "from sklearn.metrics import accuracy_score,confusion_matrix,roc_auc_score,log_loss\n",
        "#lyb for understanding model perdiction\n",
        "import shap\n",
        "shap.initjs()\n",
        "import glob\n"
      ],
      "metadata": {
        "id": "qcBEdjwECwNT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_columns', 200)\n",
        "pd.set_option('display.max_rows', 200)"
      ],
      "metadata": {
        "id": "jkCGzJMZlKN9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfa=dfn.dropna(subset = ['genres'])"
      ],
      "metadata": {
        "id": "CoHonBNgRh7z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "\n",
        "mlb = MultiLabelBinarizer(sparse_output=True)\n",
        "\n",
        "dfa = dfa.join(\n",
        "            pd.DataFrame.sparse.from_spmatrix(\n",
        "                mlb.fit_transform(dfa.pop('genres')),\n",
        "                index=dfa.index,\n",
        "                columns=mlb.classes_))"
      ],
      "metadata": {
        "id": "Hk3dYUEdSHDl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_colwidth', -1)"
      ],
      "metadata": {
        "id": "rBYAN70sEOs6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameter tuning\n",
        "\n",
        "classifier = RandomForestClassifier() # For GBM, use GradientBoostingClassifier()\n",
        "grid_values = {'n_estimators':[50, 80,  100], 'max_depth':[3, 5, 7]}\n",
        "classifier = GridSearchCV(classifier, param_grid = grid_values, scoring = 'roc_auc', cv=5)\n",
        "\n",
        "# Fit the object to train dataset\n",
        "classifier.fit(X_train, Y_train)"
      ],
      "metadata": {
        "id": "Kz_2sxpm4Ei6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of trees\n",
        "n_estimators = [50,80,100]\n",
        "\n",
        "# Maximum depth of trees\n",
        "max_depth = [4,6,8]\n",
        "\n",
        "# Minimum number of samples required to split a node\n",
        "min_samples_split = [50,100,150]\n",
        "\n",
        "# Minimum number of samples required at each leaf node\n",
        "min_samples_leaf = [40,50]\n",
        "\n",
        "# HYperparameter Grid\n",
        "param_dict = {'n_estimators' : n_estimators,\n",
        "              'max_depth' : max_depth,\n",
        "              'min_samples_split' : min_samples_split,\n",
        "              'min_samples_leaf' : min_samples_leaf}# Create an instance of the RandomForestClassifier\n",
        "rf_model = RandomForestClassifier()\n",
        "\n",
        "# Grid search\n",
        "rf_grid = GridSearchCV(estimator=rf_model,\n",
        "                       param_grid = param_dict,\n",
        "                       cv = 5, verbose=2, scoring='roc_auc')\n",
        "\n",
        "rf_grid.fit(X_train,Y_train)\n",
        "rf_grid.best_estimator_\n",
        "rf_optimal_model = rf_grid.best_estimator_\n",
        "# Making predictions on train and test data\n",
        "\n",
        "train_class_preds = rf_optimal_model.predict(X_train)\n",
        "test_class_preds = rf_optimal_model.predict(X_test)\n",
        "\n",
        "\n",
        "# Get the probabilities on train and test\n",
        "train_preds = rf_optimal_model.predict_proba(X_train)[:,1]\n",
        "test_preds = rf_optimal_model.predict_proba(X_test)[:,1]\n",
        "rf_optimal_model.feature_importances_\n",
        "importances = rf_optimal_model.feature_importances_\n",
        "\n",
        "importance_dict = {'Feature' : list(X_train.columns),\n",
        "                   'Feature Importance' : importances}\n",
        "\n",
        "importance_df = pd.DataFrame(importance_dict)\n",
        "importance_df['Feature Importance'] = round(importance_df['Feature Importance'],2)"
      ],
      "metadata": {
        "id": "IZB0mH-a4JRv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score,confusion_matrix\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import auc"
      ],
      "metadata": {
        "id": "g1Ra6_Eo4JNE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = LogisticRegression()\n",
        "rf = RandomForestClassifier()\n",
        "xgb = XGBClassifier(objective= 'binary:logistic', nthread=4, seed=42)\n",
        "param_dict_lr = {\n",
        "    'C' : [1e-6,1e-5,1e-4,1e-3,1e-2,1e-1,1,10,100,1e-3,1e+4,1e+5,1e+6]\n",
        "}\n",
        "\n",
        "param_dict_rf = {\n",
        "    'max_depth': [4, 6, 8],\n",
        "    'min_samples_leaf': [40, 50],\n",
        "    'min_samples_split': [50, 100, 150],\n",
        "    'n_estimators': [50, 80, 100]\n",
        "  }\n",
        "\n",
        "param_dict_xgb = {\n",
        "    'max_depth': range (2, 10, 1),\n",
        "    'n_estimators': range(60, 220, 40),\n",
        "    'learning_rate': [0.1, 0.05, 0.01, 0.005]\n",
        "  }\n",
        "  lr_grid = GridSearchCV(estimator=lr,\n",
        "                       param_grid = param_dict_lr,\n",
        "                       cv = 5, verbose=2, scoring='roc_auc')\n",
        "\n",
        "lr_grid.fit(X_train,y_train)\n",
        "print('Train ROC-AUC score : ', lr_grid.best_estimator_.score(X_train,y_train))\n",
        "print('Test ROC-AUC score : ', lr_grid.best_estimator_.score(X_test,y_test))\n",
        "lr_random = RandomizedSearchCV(estimator=lr,\n",
        "                       param_distributions = param_dict_lr,\n",
        "                       cv = 5, verbose=2, scoring='roc_auc')\n",
        "\n",
        "lr_random.fit(X_train,y_train)\n",
        "print('Train ROC-AUC score : ', lr_random.best_estimator_.score(X_train,y_train))\n",
        "print('Test ROC-AUC score : ', lr_random.best_estimator_.score(X_test,y_test))\n",
        "lr_bayes = BayesSearchCV(estimator=lr,\n",
        "                       search_spaces = {'C' : Real(1e-6, 1e+6, prior='log-uniform') },\n",
        "                       cv = 5, verbose=2, scoring='roc_auc', n_iter=32)\n",
        "\n",
        "lr_bayes.fit(X_train,y_train)\n",
        "lr_bayes.best_estimator_\n",
        "rf_grid = GridSearchCV(estimator=rf,\n",
        "                       param_grid = param_dict_rf,\n",
        "                       cv = 5, verbose=2, scoring='roc_auc')\n",
        "\n",
        "rf_grid.fit(X_train,y_train)\n",
        "rf_grid.best_params_\n",
        "rf_random = RandomizedSearchCV(estimator=rf,\n",
        "                       param_distributions = param_dict_rf,\n",
        "                       cv = 5, verbose=2, scoring='roc_auc')\n",
        "\n",
        "rf_random.fit(X_train,y_train)\n",
        "rf_random.best_params_\n",
        "rf_bayes = BayesSearchCV(estimator=rf,\n",
        "                       search_spaces = {\n",
        "                          'max_depth': Integer(4,8),\n",
        "                          'min_samples_leaf': Integer(10,100),\n",
        "                          'min_samples_split': Integer(50,150),\n",
        "                          'n_estimators': Integer(10,100)\n",
        "                        },\n",
        "                       cv = 5, verbose=2, scoring='roc_auc')\n",
        "\n",
        "rf_bayes.fit(X_train,y_train)\n",
        "rf_bayes.best_params_\n",
        "rf_model = rf_bayes.best_estimator_\n",
        "xgb_grid = GridSearchCV(estimator=xgb,\n",
        "                       param_grid = param_dict_xgb,\n",
        "                       cv = 5, verbose=2, scoring='roc_auc')\n",
        "\n",
        "xgb_grid.fit(X_train,y_train)\n",
        "xgb_grid.best_params_\n",
        "xgb_random = RandomizedSearchCV(estimator=xgb,\n",
        "                       param_distributions = param_dict_xgb,\n",
        "                       cv = 5, verbose=2, scoring='roc_auc')\n",
        "\n",
        "xgb_random.fit(X_train,y_train)\n",
        "xgb_random.best_params_\n",
        "xgb_bayes = BayesSearchCV(estimator=xgb,\n",
        "                       search_spaces = {\n",
        "                          'max_depth': Integer(2, 10),\n",
        "                          'n_estimators': Integer(60, 220),\n",
        "                          'learning_rate': Real(0.001, 0.1, prior='log-uniform')\n",
        "                        },\n",
        "                       cv = 5, verbose=2, scoring='roc_auc', n_jobs=10)\n",
        "\n",
        "xgb_bayes.fit(X_train,y_train)\n",
        "xgb_model = xgb_grid.best_estimator_"
      ],
      "metadata": {
        "id": "f7YYwLsu4JJ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models = [lr_model, rf_model, xgb_model]"
      ],
      "metadata": {
        "id": "usl1WjVH8jJg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_metric(models,X_train, X_test, y_train, y_test):\n",
        "\n",
        "  cols = ['Train accuracy', 'Test accuracy', 'Train precision', 'Test precision', 'Train recall', 'Test recall',\n",
        "          'Train f1 score', 'Test f1 score', 'Train ROC-AUC', 'Test ROC-AUC']\n",
        "  model_df = pd.Dataframe(columns=cols)\n",
        "  conf_train, conf_test = {}, {}\n",
        "\n",
        "  i = 0\n",
        "  for model in models:\n",
        "\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred_train = model.predict(X_train)\n",
        "    y_pred_test = model.predict(X_test)\n",
        "\n",
        "    model_df.loc[i,'Train accuracy'] = accuracy_score(y_train, y_pred_train).round(2)\n",
        "    model_df.loc[i,'Test accuracy'] = accuracy_score( y_test, y_pred_test).round(2)\n",
        "    model_df.loc[i,'Train precision'] = precision_score(y_train, y_pred_train).round(2)\n",
        "    model_df.loc[i,'Test precision'] = precision_score( y_test, y_pred_test).round(2)\n",
        "    model_df.loc[i,'Train recall'] = recall_score(y_train, y_pred_train).round(2)\n",
        "    model_df.loc[i,'Test recall'] = recall_score(y_test, y_pred_test).round(2)\n",
        "    model_df.loc[i,'Train f1 score'] = f1_score(y_train, y_pred_train).round(2)\n",
        "    model_df.loc[i,'Test f1 score'] = f1_score(y_test, y_pred_test).round(2)\n",
        "    model_df.loc[i,'Train ROC-AUC'] = roc_auc__score(y_train, y_pred_train).round(2)\n",
        "    model_df.loc[i,'Test ROC-AUC'] = roc_auc_score( y_test, y_pred_test).round(2)\n",
        "\n",
        "    conf_train[model.__class__.__name__] = confusion_matrix(y_train, y_pred_train)\n",
        "    conf_test[model.__class__.__name__] = confusion_matrix(y_test, y_pred_test)"
      ],
      "metadata": {
        "id": "D4UjIeM74I_1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_df, conf_train, conf_test = model_metric(models,X_train,y_train,X_test,y_test)"
      ],
      "metadata": {
        "id": "0h5aOBTv4I9t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcif8YWx2325",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "ee72d237-f955-4cd5-8855-4335ceb58347"
      },
      "source": [
        "model_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Train accuracy</th>\n",
              "      <th>Test accuracy</th>\n",
              "      <th>Train precision</th>\n",
              "      <th>Test precision</th>\n",
              "      <th>Train recall</th>\n",
              "      <th>Test recall</th>\n",
              "      <th>Train f1 score</th>\n",
              "      <th>Test f1 score</th>\n",
              "      <th>Train ROC-AUC</th>\n",
              "      <th>Test ROC-AUC</th>\n",
              "      <th>Model Name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.59</td>\n",
              "      <td>0.58</td>\n",
              "      <td>0.61</td>\n",
              "      <td>0.61</td>\n",
              "      <td>0.71</td>\n",
              "      <td>0.71</td>\n",
              "      <td>LogisticRegression</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.81</td>\n",
              "      <td>0.81</td>\n",
              "      <td>0.77</td>\n",
              "      <td>0.76</td>\n",
              "      <td>0.61</td>\n",
              "      <td>0.59</td>\n",
              "      <td>0.68</td>\n",
              "      <td>0.67</td>\n",
              "      <td>0.76</td>\n",
              "      <td>0.75</td>\n",
              "      <td>RandomForestClassifier</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.86</td>\n",
              "      <td>0.83</td>\n",
              "      <td>0.77</td>\n",
              "      <td>0.74</td>\n",
              "      <td>0.81</td>\n",
              "      <td>0.76</td>\n",
              "      <td>0.79</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.85</td>\n",
              "      <td>0.81</td>\n",
              "      <td>XGBClassifier</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Train accuracy Test accuracy  ... Test ROC-AUC              Model Name\n",
              "0           0.75          0.75  ...         0.71      LogisticRegression\n",
              "1           0.81          0.81  ...         0.75  RandomForestClassifier\n",
              "2           0.86          0.83  ...         0.81           XGBClassifier\n",
              "\n",
              "[3 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import KNeighborsClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "#Setup arrays to store training and test accuracies\n",
        "neighbors = np.arange(1,9)\n",
        "train_accuracy =np.empty(len(neighbors))\n",
        "test_accuracy = np.empty(len(neighbors))\n",
        "\n",
        "for i,k in enumerate(neighbors):\n",
        "    # Setup a knn classifier with k neighbors\n",
        "    knn = KNeighborsClassifier(n_neighbors=k)\n",
        "\n",
        "    # Fit the model\n",
        "    knn.fit(X_train, y_train)\n",
        "\n",
        "    # Compute accuracy on the training set\n",
        "    train_accuracy[i] = knn.score(X_train, y_train)\n",
        "\n",
        "    # Compute accuracy on the test set\n",
        "    test_accuracy[i] = knn.score(X_test, y_test)"
      ],
      "metadata": {
        "id": "YnO36atx4I50"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# In case of classifier like knn the parameter to be tuned is n_neighbors\n",
        "param_grid = {'n_neighbors':np.arange(1,50)}"
      ],
      "metadata": {
        "id": "p39XEduX4I2J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "knn = KNeighborsClassifier()\n",
        "knn_cv= GridSearchCV(knn,param_grid,cv=5)\n",
        "knn_cv.fit(X,y)\n",
        "knn_cv.best_params_"
      ],
      "metadata": {
        "id": "QC4UMGXR4Izd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#naive bayes classifier."
      ],
      "metadata": {
        "id": "KwxqC8BO4Itt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "1220b3cc2df7226c69142385389249f6184431f0",
        "id": "n0kFql08xLYh"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "msg_train,msg_test,label_train,label_test = train_test_split(message['tokenized_message'],message['label'],test_size=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltHiuyb2Gdxg"
      },
      "source": [
        "train_array= train_vectorized.toarray()\n",
        "test_array = test_vectorized.toarray()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "9ae436fe7af2fca2dc7b0fd25d44567c88aa24b8",
        "id": "HLrQuWVyxLYf"
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "spam_detect_model = GaussianNB().fit(train_array,label_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "koOOJdf0FTks"
      },
      "source": [
        "train_preds = spam_detect_model.predict(train_array)\n",
        "test_preds = spam_detect_model.predict(test_array)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "03ac047e8e9e996e7723e901bf00fd7478ab9755",
        "id": "SCJo7wD7xLYg"
      },
      "source": [
        "from sklearn.metrics import classification_report,confusion_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mb0ocgK0G8Vk",
        "outputId": "727d48f8-9306-48ce-8c97-d05c0264cf44"
      },
      "source": [
        "# Confusion matrices for train and test\n",
        "\n",
        "print(confusion_matrix(label_train,train_preds))\n",
        "print(confusion_matrix(label_test,test_preds))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[2958  911]\n",
            " [   0  588]]\n",
            "[[724 232]\n",
            " [ 11 148]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tXUONUulFoBm",
        "outputId": "45355f1a-aecf-4801-f2e8-5db4d573f5a5"
      },
      "source": [
        "# Print the classification report for train and test\n",
        "print(classification_report(label_train,train_preds))\n",
        "print(\"\\n\")\n",
        "print(classification_report(label_test,test_preds))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       1.00      0.76      0.87      3869\n",
            "        spam       0.39      1.00      0.56       588\n",
            "\n",
            "    accuracy                           0.80      4457\n",
            "   macro avg       0.70      0.88      0.72      4457\n",
            "weighted avg       0.92      0.80      0.83      4457\n",
            "\n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.99      0.76      0.86       956\n",
            "        spam       0.39      0.93      0.55       159\n",
            "\n",
            "    accuracy                           0.78      1115\n",
            "   macro avg       0.69      0.84      0.70      1115\n",
            "weighted avg       0.90      0.78      0.81      1115\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sWxlMwv9hcLR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aoWn1v6W4OJJ"
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "spam_detect_model = GaussianNB().fit(train_array,label_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_igV3G-4XOL"
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "spam_detect_model = MultinomialNB().fit(train_array,label_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2YplIR65FdY"
      },
      "source": [
        "`````````` from sklearn.naive_bayes import BernoulliNB\n",
        "spam_detect_model = BernoulliNB().fit(train_array,label_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mWD98lUwvsx9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zs4yapPa49xl"
      },
      "source": [
        "from sklearn import svm\n",
        "clf = svm.SVC()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vuZBNf2Y5NIq",
        "outputId": "afd42cf2-0599-4ee5-8660-047947b20bca"
      },
      "source": [
        " clf.fit(train_vectorized, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
              "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
              "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
              "    tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajwZ-ab588qs"
      },
      "source": [
        "test_pred=clf.predict(test_vectorized)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2g479Sfx9DeT",
        "outputId": "9430e3df-84ec-4a6a-a5f9-df8ffa860407"
      },
      "source": [
        "# Confusion matrices for train and test\n",
        "\n",
        "print(confusion_matrix(y_train,train_pred))\n",
        "print(confusion_matrix(y_test,test_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[5483   23]\n",
            " [ 166 1252]]\n",
            "[[3585   87]\n",
            " [ 376  569]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OBJ9OCiSv4LD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7M6d8KZSFKLQ"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cCuFfcWGzhi"
      },
      "source": [
        "param_dict = {'C': [0.1, 1, 10, 1000],\n",
        "              'gamma': [1, 0.1, 0.01, 0.0001],\n",
        "              'kernel': ['rbf','linear','poly']}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lclw78TOITx-"
      },
      "source": [
        "grid = GridSearchCV(clf, param_dict,n_jobs=2, cv=5, verbose = 10,scoring='accuracy')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aP2-63z4fOi6"
      },
      "source": [
        "grid.fit(train_vectorized,y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lgp3HZQhfTyy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e153ecc2-e357-40be-84ad-d8bd283ad6ee"
      },
      "source": [
        "grid.best_params_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'C': 10, 'gamma': 0.01, 'kernel': 'rbf'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zECNO6a7Vj7S"
      },
      "source": [
        "g_pred_tr=grid.predict(train_vectorized)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a18Xgh2sVx5k"
      },
      "source": [
        "g_pred_test=grid.predict(test_vectorized)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cx4QJntEWyPO",
        "outputId": "9b287a55-10de-4186-8dc2-58734bff3a66"
      },
      "source": [
        "# Confusion matrices for train and test\n",
        "\n",
        "print(confusion_matrix(y_train,g_pred_tr))\n",
        "print(confusion_matrix(y_test,g_pred_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[5467   39]\n",
            " [ 117 1301]]\n",
            "[[3531  141]\n",
            " [ 266  679]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "for i in dataset.columns.tolist():\n",
        "  print(\"No. of unique values in \",i,\"is\",dataset[i].nunique(),\".\")"
      ],
      "metadata": {
        "id": "YNSYg7PKAh9W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f = open(\"/content/drive/MyDrive/demofile1.txt\", \"a\")\n",
        "f.write(\"this is also\")\n",
        "f.close()\n",
        "\n",
        "#open and read the file after the appending:\n",
        "f = open(\"/content/drive/MyDrive/demofile1.txt\", \"r\")\n",
        "print(f.read())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qxefp_nAzJ44",
        "outputId": "a45c114d-5776-4e49-e49e-8706d711cc53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Now the file has more content!this is also\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n=2\n",
        "print(f\"{n} is the thing\")"
      ],
      "metadata": {
        "id": "jSZMm2uRzWqI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03372abb-c9ad-46ba-9119-8c65db109f9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2 is the thing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### K S Chart"
      ],
      "metadata": {
        "id": "3UgBzx_TUn4m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ks(data=None,target=None, prob=None):\n",
        "    data['target0'] = 1 - data[target]\n",
        "    data['bucket'] = pd.qcut(data[prob], 10)\n",
        "    grouped = data.groupby('bucket', as_index = False)\n",
        "    kstable = pd.DataFrame()\n",
        "    kstable['min_prob'] = grouped.min()[prob]\n",
        "    kstable['max_prob'] = grouped.max()[prob]\n",
        "    kstable['events']   = grouped.sum()[target]\n",
        "    kstable['nonevents'] = grouped.sum()['target0']\n",
        "    kstable = kstable.sort_values(by=\"min_prob\", ascending=False).reset_index(drop = True)\n",
        "    kstable['event_rate'] = (kstable.events / data[target].sum()).apply('{0:.2%}'.format)\n",
        "    kstable['nonevent_rate'] = (kstable.nonevents / data['target0'].sum()).apply('{0:.2%}'.format)\n",
        "    kstable['cum_eventrate']=(kstable.events / data[target].sum()).cumsum()\n",
        "    kstable['cum_noneventrate']=(kstable.nonevents / data['target0'].sum()).cumsum()\n",
        "    kstable['KS'] = np.round(kstable['cum_eventrate']-kstable['cum_noneventrate'], 3) * 100\n",
        "\n",
        "    #Formating\n",
        "    kstable['cum_eventrate']= kstable['cum_eventrate'].apply('{0:.2%}'.format)\n",
        "    kstable['cum_noneventrate']= kstable['cum_noneventrate'].apply('{0:.2%}'.format)\n",
        "    kstable.index = range(1,11)\n",
        "    kstable.index.rename('Decile', inplace=True)\n",
        "    pd.set_option('display.max_columns', 9)\n",
        "    print(kstable)\n",
        "\n",
        "    #Display KS\n",
        "    from colorama import Fore\n",
        "    print(Fore.RED + \"KS is \" + str(max(kstable['KS']))+\"%\"+ \" at decile \" + str((kstable.index[kstable['KS']==max(kstable['KS'])][0])))\n",
        "    return(kstable)"
      ],
      "metadata": {
        "id": "3YI1No55WZ9L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mydf = ks(data=df,target=\"y\", prob=\"p\")"
      ],
      "metadata": {
        "id": "gOdTGKUsUva-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}