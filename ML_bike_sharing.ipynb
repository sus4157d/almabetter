{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sus4157d/almabetter/blob/main/ML_bike_sharing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    -Bike sharing demand prediction\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Regression\n",
        "##### **Contribution**    - Individual\n"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have dataset of seaul city in which we have firstly -Rented Bike count in particular hour . Purpose is to train a model to predict the Need of Bike count for any hour in particular day in year. (day and hour are our independent variable ) . The \"Rented Bike Sharing Demand\" is what we need to predict for any given conditions .\n",
        "Next- we have dataset columns\n",
        "'Date','Hour','Temperature(°C)', 'Humidity(%)',\n",
        "'Wind speed (m/s)', 'Visibility (10m)', 'Dew point temperature(°C)',\n",
        "'Solar Radiation (MJ/m2)', 'Rainfall(mm)', 'Snowfall (cm)', 'Seasons',\n",
        "'Holiday', 'Functioning Day'\n",
        "Which are independent variable for predicting dependent variable.\n",
        "I have gone through each column and understand the values it have. Did some Data wrangling like cleaning and modifing data. We have 'Date' feature which i have used for creating feature like \"Day_month\",\"week_number\",\"day_year\",\"day_week\". these are-what date is?,what week number fall on that day? what day of year is that day is? which day of week is this day? these extraction is usefull to determine the demand according to day in week as we have different shedule in different days . I have ploted their relationship with  our dependent variable . that is positive correlation for 'hour' and 'Temp' feature. But for 'humidity','rain','snow' have negative correlation with demand of bike.\n",
        " Next 'day in year' is also important to see weather determination for that day like if it will be spring or summer .\n",
        "We have next columns describing weather condition of day or hour like we have \"Temp\",\"visibility\",\"rain\",\"snow\", etc which have their relation with bike demand for that day.\n",
        "I have ploted distibution of 'bike_count ' which is positive skewed . as i need to apply square root transformation to make it normal . we have some values of it zero so we cannt apply log transformation.\n",
        "Next we have correlation heatmap which is very high for some features like \"Temp\" and \"Dp_temp\" , also for \"day_month\",\"day_week\" with \"week_number\" so we removed some of them . calculated vif for numeric feature which is less than 10 which is good count. Next we have categorical feature we need to one hot encoding for it now we are ready for spliting data and modeling fit. I have applied LinearRegression form sklearn for modeling and fitting with GridSearch cross validation and Hypertunning with Lasso and Ridge . I Have also used statsmodel.api for modeling which had a better Evaluation Matrix value ."
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/sus4157d/almabetter.git"
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "poVoeSqjKDIj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need to train a model which will predict demand of bike for a city for a patricular hour for a particular day with given condition of weather given. We need to predict this demand for bike earlier so that we can get ready for situation."
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from numpy import math\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import statsmodels.api as sm\n",
        "import statsmodels.formula.api as smf\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from scipy.stats import zscore\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from datetime import date\n",
        "from datetime import datetime"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "xNeLCBr2aFQI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "df=pd.read_csv(\"/content/drive/MyDrive/SeoulBikeData.csv\",encoding = \"ISO-8859-1\")"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "df.tail()"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "df.shape"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "df.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "len(df[df.duplicated()])"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "df.info()"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "No NULL values present"
      ],
      "metadata": {
        "id": "M-MYecOw2to2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have \"rent_bike_count\" for dv and 12 more column which are idv. We dont have nan value in data set. mostly have numerical(int and float) datatypes but object are also there which need to interperate. we firstly prepare for numerical data than for categorical data will be given."
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding  Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "df.columns"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "df.describe()"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "c6UMWoSY7X6i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.Date.unique()"
      ],
      "metadata": {
        "id": "gf20rwEF7BgY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"Rented Bike Count\"].unique()"
      ],
      "metadata": {
        "id": "1QfXYdOL7Ud8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"Hour\"].unique()"
      ],
      "metadata": {
        "id": "mogOFLsH7xj8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"Temperature(°C)\"].unique()"
      ],
      "metadata": {
        "id": "vrXfMmA973KV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Humidity(%)'].unique()"
      ],
      "metadata": {
        "id": "O2peVNdtBj12"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Wind speed (m/s)'].unique()"
      ],
      "metadata": {
        "id": "tYf2yf6iBxvg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Visibility (10m)'].unique()"
      ],
      "metadata": {
        "id": "T-irUyI5B_Sa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Dew point temperature(°C)'].unique()"
      ],
      "metadata": {
        "id": "O0poMMDcCHDD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Solar Radiation (MJ/m2)'].unique()"
      ],
      "metadata": {
        "id": "IOIlI0XWCUVy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Rainfall(mm)'].unique()"
      ],
      "metadata": {
        "id": "gl6Mg983CkbT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Snowfall (cm)'].unique()"
      ],
      "metadata": {
        "id": "UipZB5zaCuYn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Seasons'].unique()"
      ],
      "metadata": {
        "id": "TPwSVM0JC-0m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Holiday'].unique()"
      ],
      "metadata": {
        "id": "Qf0CjcF9DMYf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[ 'Functioning Day'].unique()"
      ],
      "metadata": {
        "id": "4X7BwdjKDRRG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "NXuDwTw6k-Bs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Renaming the columns for better typing\n",
        "df.rename(columns={\"Rented Bike Count\":\"Rent_bike_count\",\"Temperature(°C)\":\"Temp\",\"Humidity(%)\":\"Humidity\",\"Wind speed (m/s)\":\"Wind_speed\",\"Visibility (10m)\":\"Visibility\",\"Dew point temperature(°C)\":\"Dp_temp\",\"Solar Radiation (MJ/m2)\":\"Solar_rad\",\"Rainfall(mm)\":\"Rain\",\"Snowfall (cm)\":\"Snow\",\"Functioning Day\":\"Funct_day\"},inplace=True)"
      ],
      "metadata": {
        "id": "nGtb6unM-IDf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# converting date to week no.\n",
        "df['Date']=pd.to_datetime(df['Date'])\n",
        "df['Week_number'] = df['Date'].dt.isocalendar().week"
      ],
      "metadata": {
        "id": "5l3zKoRcze1Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# getting the day in mounth and mounth in year and day in year and day in week\n",
        "df['day_year']=df['Date'].dt.dayofyear\n",
        "df['day']=df[\"Date\"].dt.day\n",
        "df['month']=df[\"Date\"].dt.month\n",
        "df['day_week']=df['Date'].dt.weekday"
      ],
      "metadata": {
        "id": "TNdIsyOZMroV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Week_number']=df['Week_number'].astype(np.int64)"
      ],
      "metadata": {
        "id": "hnO-lIfzfOXl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"Temp\"]=df['Temp'].astype(int)\n",
        "df['Wind_speed']=df[\"Wind_speed\"].astype(int)\n",
        "df['Snow']=df[\"Snow\"].astype(int)\n",
        "df['Rain']=df[\"Rain\"].astype(int)\n",
        "df['Dp_temp']=df[\"Dp_temp\"].astype(int)\n",
        "df['Solar_rad']=df[\"Solar_rad\"].astype(int)\n"
      ],
      "metadata": {
        "id": "0Dv3eDailfG4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#getting total hour rented per week\n",
        "df['total_hour']=df.groupby([\"Week_number\"]).Hour.sum()\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.plot(df['total_hour'])\n",
        "plt.title(\"Total Rented Hours for week number\")\n",
        "plt.xlabel(\"week number\")\n",
        "plt.ylabel(\"total rented hours\")"
      ],
      "metadata": {
        "id": "K-rATyh-EArl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For some week we have less than normal demand for bikes (8,11,46) weeks but some week have (45,50,10,7) more demand of bikes than normal or average day."
      ],
      "metadata": {
        "id": "L4NC-AHAitaw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#getting int value\n",
        "df['total_hour'].fillna(0,inplace=True)\n",
        "df['total_hour']=df['total_hour'].astype(int)"
      ],
      "metadata": {
        "id": "3LQZaD43eJME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# getting differnt temp ranges and rented bike count\n",
        "df['Temp_r']=df['Temp'].apply(lambda x:0 if x<4.1 else(1 if x<8.1 else( 2 if x< 13 else( 3 if x< 18 else ( 4 if x<24 else (5 if x<29 else(6 if x<35 else 7)))))) )\n",
        "df.groupby('Temp_r')['Rent_bike_count'].sum()\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.plot(df.groupby('Temp_r')['Rent_bike_count'].sum())\n",
        "plt.title(\"Total Bike rented in diff temp range\")\n",
        "plt.xlabel(\"Temp from -17 to 39 degrees\")\n",
        "plt.ylabel(\"Total Bike Rented\")\n",
        "\n"
      ],
      "metadata": {
        "id": "stbZqL01NKbw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have divided temp in different range and had total \"rented_bike_count' counts which shows firstly decreasing slightly and then increasing trend with temp increase."
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ploting our dependent variabel that is Rented_bike_count"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "vdgLhGhofZlm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8,5))\n",
        "sns.distplot(df['Rent_bike_count'],color='y')"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is positively skewed distribution for 'Rent_bike_count' we need some transformation to make is normally distributed."
      ],
      "metadata": {
        "id": "7Uro8hF4j35Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ploting with Log10 transformation\n",
        "plt.figure(figsize=(8,5))\n",
        "sns.distplot(np.sqrt(df['Rent_bike_count']),color='y')"
      ],
      "metadata": {
        "id": "XcKeKGAreG1v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Its the dependent variable . It is important to find out that if this chart is normally distributed. if not normally distributed we apply some transformation to it."
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "our dv contains zero value so we cannt apply log or inverse transformation but go with square root transformation."
      ],
      "metadata": {
        "id": "AdSW8bZ8oe_n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below are the some type of method or way to deal above type of problem.\n",
        "\n",
        "square-root for moderate skew: sqrt(x) for positively skewed data, sqrt(max(x+1) - x) for negatively skewed data\n",
        "\n",
        "log for greater skew: log10(x) for positively skewed data, log10(max(x+1) - x) for negatively skewed data\n",
        "\n",
        "inverse for severe skew: 1/x for positively skewed data 1/(max(x+1) - x) for negatively skewed data"
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ploting Numerical Columns of features"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "2bKVvJEdYiiy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_f=df.describe().columns"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for col in num_f[1:]:\n",
        "  fig=plt.figure(figsize=(8,5))\n",
        "  ax=fig.gca()\n",
        "  feature=df[col]\n",
        "  feature.hist(bins=50,ax=ax)\n",
        "  ax.set_title(col)\n",
        "  ax.axvline(feature.mean(),color='red',linestyle='dashed',linewidth=2)\n",
        "  ax.axvline(feature.median(),color='gray',linestyle='dashed',linewidth=2)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "Y2lp5V0rpKEG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I am ploting all feature variable . to know which type of distibution these varible have .If these are not normally distributed then we can have some transformation applied to these."
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "GFF_7Ab7mopx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "we have some feature like 'Temp','Humidity' have normal distibution but 'windspeed','Solar_rad','Rain',\"Snow\" etc have positive distribution where as 'visibility'have negative distribution ."
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "-JiQyfWJYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For better trained model fit and prediction we need to have normally distributed data . Here we need to apply squareroot transformation for postive and for negative sqrt(max(x+1) - x) transformation."
      ],
      "metadata": {
        "id": "BcBbebzrYklV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Transforming the feature with log transformation"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_f=num_f.drop(\"Visibility\")"
      ],
      "metadata": {
        "id": "P4B7UY64zPRe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_f=num_f.drop(\"Rent_bike_count\")"
      ],
      "metadata": {
        "id": "CUe0VgDF0DDP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for col in num_f[:]:\n",
        "  fig=plt.figure(figsize=(8,5))\n",
        "  ax=fig.gca()\n",
        "  feature=np.sqrt(df[col])\n",
        "  feature.hist(bins=50,ax=ax)\n",
        "  ax.set_title(col)\n",
        "  ax.axvline(feature.mean(),color='red',linestyle='dashed',linewidth=2)\n",
        "  ax.axvline(feature.median(),color='gray',linestyle='dashed',linewidth=2)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "  fig=plt.figure(figsize=(8,5))\n",
        "  ax=fig.gca()\n",
        "  feature=np.sqrt(max(df[\"Visibility\"]+1) - df[\"Visibility\"])\n",
        "  feature.hist(bins=50,ax=ax)\n",
        "  ax.set_title(\"Visibility\")\n",
        "  ax.axvline(feature.mean(),color='red',linestyle='dashed',linewidth=2)\n",
        "  ax.axvline(feature.median(),color='gray',linestyle='dashed',linewidth=2)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "OHiOEq7M0kBF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For \"Visibility\" we have used sqrt(max(x+1) - x) transformation where as for \"Temp\",\"Dp_temp\",\"Wind_speed\",\"Rain\",\"Snow\" etc we have applied squareroot transformation."
      ],
      "metadata": {
        "id": "zfJ8IqMcYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Drawing Relationship between Dependent Variable and Independent Varaiable"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#scatter plot\n",
        "num_f=df.describe().columns\n",
        "num_f=num_f.drop(\"Rent_bike_count\")\n",
        "num_f"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for col in num_f[:]:\n",
        "  fig=plt.figure(figsize=(8,5))\n",
        "  ax=fig.gca()\n",
        "  feature=df[col]\n",
        "  label=df['Rent_bike_count']\n",
        "  correlation=label.corr(feature)\n",
        "  plt.scatter(x=feature,y=label)\n",
        "  plt.ylabel(\"Bike_count\")\n",
        "  plt.xlabel(col)\n",
        "  plt.title(\"Bike_count vs \" + col + \"--correlation \"+str(correlation))\n",
        "  z=np.polyfit(feature,label,1)\n",
        "  y_hat=np.poly1d(z)(feature)\n",
        "  plt.plot(feature,y_hat,\"r--\",lw=1)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hXOkJ1flaAg1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "iky9q4vBYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we need to draw Relationship between Dependent varible and feature variable that is independent varible . we have ploted linear regression line for all feature. which tells the relation ship."
      ],
      "metadata": {
        "id": "aJRCwT6DYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "F6T5p64dYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have some feature with positive correlation and some feature with negative correlation  for which we need to find coefficent to train the model."
      ],
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Correlation Heatmap"
      ],
      "metadata": {
        "id": "NC_X3p0fY2L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Heatmap\n",
        "plt.figure(figsize=(18,15))\n",
        "correlation=df.corr()\n",
        "sns.heatmap(abs(correlation),annot=True,cmap=\"coolwarm\")"
      ],
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From correlation Heatmap it is clear that \"week_number\",\"Temp_r\",\"month\",\"Dp_temp\" shows high multicolinearity so we removed these features .\n",
        "Where as \"hour\",\"temp\",\"humidity\",\"wind_speed\",\"day\",\"day_year\",\"day_week\",\"snow\",\"rain\" show good relation with \"rent_bike_count\" which is good for our model."
      ],
      "metadata": {
        "id": "bfSqtnDqZNRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Dealing Multicolinearity"
      ],
      "metadata": {
        "id": "ceWtwMId0K6A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Multicolinearity\n",
        "def calc_vif(X):\n",
        "\n",
        "   # Calculating VIF\n",
        "   vif = pd.DataFrame()\n",
        "   vif[\"variables\"] = X.columns\n",
        "   vif[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
        "\n",
        "   return(vif)"
      ],
      "metadata": {
        "id": "mPe__kyS0J_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vif=calc_vif(df[[i for i in df.describe().columns if i not in ['month','Week_number','Rent_bike_count','Temp_r',\"Dp_temp\"]]])"
      ],
      "metadata": {
        "id": "clDRsrn81Dc2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vif"
      ],
      "metadata": {
        "id": "WhNTWZPE6N5h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### We got vif less then 6.589 which is good for us to carry linear Regression."
      ],
      "metadata": {
        "id": "CSk03L5g4Q0b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_f=list(vif['variables'])"
      ],
      "metadata": {
        "id": "wG8ha7Kc6Ue9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_f"
      ],
      "metadata": {
        "id": "ZkoZSIQ_6ZL7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Analysis of Categorical Data"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cat_f=df.describe(include=['object','category']).columns\n",
        "cat_f"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for col in cat_f:\n",
        "  counts=df[col].value_counts().sort_index()\n",
        "  fig=plt.figure(figsize=(8,5))\n",
        "  ax=fig.gca()\n",
        "  counts.plot.bar(ax=ax,color='red')\n",
        "  plt.title(col + \" counts \")\n",
        "  plt.xlabel(col)\n",
        "  plt.ylabel(\"freq\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "b49Lehr7vr5X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This chart show catogorical feature and there value count on plot ."
      ],
      "metadata": {
        "id": "eMmPjTByveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### boxplot for label for each col"
      ],
      "metadata": {
        "id": "uE_nayK59emp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ploting box for each col\n",
        "for col in cat_f:\n",
        "  fig=plt.figure(figsize=(8,5))\n",
        "  ax=fig.gca()\n",
        "  df.boxplot(column=\"Rent_bike_count\",by=col,ax=ax)\n",
        "  ax.set_title(\"label by \"+col)\n",
        "  ax.set_title(\"Bike_count\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jZugFGJj9bNH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "we have boxplot for each categorical feature with respect to label . This plot shows that we have outlier in our values of bike count .we need to take care of these."
      ],
      "metadata": {
        "id": "1wXfMYNtq0ZF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Engineering & Data Pre-processing"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Missing Values & Missing Value Imputation\n",
        "df.info()"
      ],
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We dont have missing value."
      ],
      "metadata": {
        "id": "uByvkXtlGbSD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing"
      ],
      "metadata": {
        "id": "YNOw_iX9GrM9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "EHEhNhTxGyMr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfc=df.copy()"
      ],
      "metadata": {
        "id": "wiApf0FQGuZq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfc.shape"
      ],
      "metadata": {
        "id": "4GojDx8EG3e0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Categorical Encoding"
      ],
      "metadata": {
        "id": "89xtkJwZ18nB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We shall convert categorical features to numeric type..."
      ],
      "metadata": {
        "id": "-6ndGTkwHD4y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode your categorical columns\n",
        "encoder_num={'Holiday':{'Holiday':0,'No Holiday':1},\n",
        "             'Funct_day':{'No':0,'Yes':1}}\n",
        "dfc=dfc.replace(encoder_num)"
      ],
      "metadata": {
        "id": "21JmIYMG2hEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#One Hot Encoding\n",
        "dfc=pd.get_dummies(dfc,columns=[\"Seasons\"],prefix=[\"Seasons\"])"
      ],
      "metadata": {
        "id": "88SZV-3FI-6B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfc.head()"
      ],
      "metadata": {
        "id": "i867MVyKKHqP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##with the help of One Hot Encoding\n",
        "###Holiday is divided in two attribute.\n",
        "###Funct_day is divided in two new attribute"
      ],
      "metadata": {
        "id": "9zUzhJHhKx8H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dfc.columns"
      ],
      "metadata": {
        "id": "pugErSRQLjoN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature=num_f"
      ],
      "metadata": {
        "id": "-1M8A3mDLni7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature.extend(['Funct_day', 'Holiday','Seasons_Autumn',\t'Seasons_Spring',\t'Seasons_Summer',\t'Seasons_Winter'])"
      ],
      "metadata": {
        "id": "2IL-T44lt-Wm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature"
      ],
      "metadata": {
        "id": "cyGNe1fxLncg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#scaling of idv\n",
        "X=dfc[feature].apply(zscore)"
      ],
      "metadata": {
        "id": "TqgutWrsNQIq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y=np.sqrt(dfc[\"Rent_bike_count\"])"
      ],
      "metadata": {
        "id": "CmNUTwGkNaKa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Data Splitting"
      ],
      "metadata": {
        "id": "BhH2vgX9EjGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split your data to train and test. Choose Splitting ratio wisely.\n",
        "X_train, X_test, y_train, y_test = train_test_split( X,y , test_size = 0.2, random_state = 0)\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "metadata": {
        "id": "0CTyd2UwEyNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's now begin to train out regression model! We will need to first split up our data into an train array that contains the part of dataset used for training data, and a test array used for test data."
      ],
      "metadata": {
        "id": "S-18IWA-n0Wr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation\n",
        "# Fit the Algorithm\n",
        "reg = LinearRegression().fit(X_train, y_train)\n",
        "print(reg.score(X_train, y_train))\n",
        "print(reg.coef_)\n",
        "\n",
        "# Predict on the model\n",
        "y_pred = reg.predict(X_test)"
      ],
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "ArJBuiUVfxKd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here are three common evaluation metrics for regression problems:\n",
        "\n",
        "Mean Absolute Error (MAE) is the mean of the absolute value of the errors:\n",
        "\n",
        "1n∑i=1n|yi−y^i|\n",
        "\n",
        "Mean Squared Error (MSE) is the mean of the squared errors:\n",
        "\n",
        "1n∑i=1n(yi−y^i)2\n",
        "\n",
        "Root Mean Squared Error (RMSE) bold text is the square root of the mean of the squared errors:\n",
        "\n",
        "1n∑i=√1n(yi−y^i)2\n",
        "\n",
        "Comparing these metrics:\n",
        "\n",
        "MAE is the easiest to understand, because it's the average error.\n",
        "MSE is more popular than MAE, because MSE \"punishes\" larger errors, which tends to be useful in the real world.\n",
        "RMSE is even more popular than MSE, because RMSE is interpretable in the \"y\" units.\n",
        "All of these are loss functions, because we want to minimize them."
      ],
      "metadata": {
        "id": "GXisqYQCoMwc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "def eval_metric(y_test,y_pred):\n",
        "  MSE  = mean_squared_error((y_test)**2, (y_pred)**2)\n",
        "  print(\"MSE :\" , MSE)\n",
        "\n",
        "  MAE=mean_absolute_error((y_test)**2, (y_pred)**2)\n",
        "  print(\"MAE :\" ,MAE)\n",
        "\n",
        "  RMSE = np.sqrt(MSE)\n",
        "  print(\"RMSE :\" ,RMSE)\n",
        "\n",
        "  r2 = r2_score((y_test)**2, (y_pred)**2)\n",
        "  print(\"R2 :\" ,r2)\n",
        "  print(\"Adjusted R2 : \",1-(1-r2_score((y_test)**2, (y_pred)**2))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)))"
      ],
      "metadata": {
        "id": "rqD5ZohzfxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_metric(y_test,y_pred)"
      ],
      "metadata": {
        "id": "2BLiIqOMQ_JU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter((y_test)**2, (y_pred)**2)\n",
        "plt.xlabel('Actual')\n",
        "plt.ylabel('Predicted')"
      ],
      "metadata": {
        "id": "cLRLqUhfScyi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,10))\n",
        "plt.plot((y_pred)**2)\n",
        "plt.plot(np.array((y_test)**2))\n",
        "plt.legend([\"Predicted\",\"Actual\"])\n",
        "plt.xlabel('No of Test Data')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "w9ZXHD3-SpOe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If We see above graph our prediction is quiet good.!:)"
      ],
      "metadata": {
        "id": "ZtuXqsocS3Rd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Residuals:"
      ],
      "metadata": {
        "id": "H4s1B_pacb_R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A residual is the vertical distance between a data point and the regression line. Each data point has one residual. They are positive if they are above the regression line and negative if they are below the regression line"
      ],
      "metadata": {
        "id": "cVrzmqQVozC2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig=plt.figure(figsize=(8,8))\n",
        "\n",
        "sns.distplot(((y_test)**2- (y_pred)**2),bins=20)\n",
        "\n",
        "#Plot Label\n",
        "fig.suptitle('Residual Analysis', fontsize = 20)"
      ],
      "metadata": {
        "id": "8DXOBeCRb-LM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "4qY1EAkEfxKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##with Lasso"
      ],
      "metadata": {
        "id": "L-GQIX0MRaM7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "lasso = Lasso()\n",
        "parameters = {'alpha': [1e-15,1e-13,1e-10,1e-8,1e-5,1e-4,1e-3,.011,1e-2,.008,1e-1,1,5,10,20,30,40,45,50,55,60,100]}\n",
        "# Fit the Algorithm\n",
        "lasso_regressor = GridSearchCV(lasso, parameters, scoring='neg_mean_squared_error', cv=4)\n",
        "lasso_regressor.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "Dy61ujd6fxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The best fit alpha value is found out to be :\" ,lasso_regressor.best_params_)\n",
        "print(\"\\nUsing \",lasso_regressor.best_params_, \" the negative mean squared error is: \", lasso_regressor.best_score_)"
      ],
      "metadata": {
        "id": "ROybSj0-hN9f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on the model\n",
        "y_pred_lasso = lasso_regressor.predict(X_test)"
      ],
      "metadata": {
        "id": "Taa3is-_hYDr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Evaluation metrics"
      ],
      "metadata": {
        "id": "4feouRxtRngQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eval_metric(y_test,y_pred_lasso)"
      ],
      "metadata": {
        "id": "ce5XZhdUhehz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,10))\n",
        "plt.plot((y_pred_lasso)**2)\n",
        "plt.plot(np.array((y_test))**2)\n",
        "plt.legend([\"Predicted\",\"Actual\"])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NVoIs4m-Qe6_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Resuldual Analysis\n",
        "fig=plt.figure(figsize=(8,8))\n",
        "\n",
        "sns.distplot(((y_test)**2- (y_pred_lasso)**2),bins=20,color='r')\n",
        "\n",
        "#Plot Label\n",
        "fig.suptitle('Residual Analysis', fontsize = 20)"
      ],
      "metadata": {
        "id": "Ef6ODuJFQWxr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Heteroscadacity\n",
        "plt.scatter((y_pred_lasso)**2,(y_test)**2-(y_pred_lasso)**2,c='r')\n",
        "plt.xlabel('Predicted selling price')\n",
        "plt.ylabel('residuals')"
      ],
      "metadata": {
        "id": "HqqkDhU3QOp7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Hyperperameter tuning and cross validation with Ridge"
      ],
      "metadata": {
        "id": "_G2Q6LMHQlQq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperprarameter tuning with Ridge\n",
        "ridge = Ridge()\n",
        "parameters = {'alpha': [1e-15,1e-10,1e-8,1e-5,1e-4,1e-3,1e-2,1,5,9,10,11,20,30,40,45,50,55,60,100,9]}\n",
        "ridge_regressor = GridSearchCV(ridge, parameters, scoring='neg_mean_squared_error', cv=3)\n",
        "ridge_regressor.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "Jp6l5V9oh0Ln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The best fit alpha value is found out to be :\" ,ridge_regressor.best_params_)\n",
        "print(\"\\nUsing \",ridge_regressor.best_params_, \" the negative mean squared error is: \", ridge_regressor.best_score_)"
      ],
      "metadata": {
        "id": "VR13xoOliQdS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_ridge = ridge_regressor.predict(X_test)"
      ],
      "metadata": {
        "id": "knc1SYRSiYFd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Evaluation metrics"
      ],
      "metadata": {
        "id": "yYQsFMtZRxW_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eval_metric(y_test,y_pred_ridge)"
      ],
      "metadata": {
        "id": "7KJGnJ5Cide-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,10))\n",
        "plt.plot((y_pred_ridge)**2)\n",
        "plt.plot((np.array(y_test))**2)\n",
        "plt.legend([\"Predicted\",\"Actual\"])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-s4CXFLOAlq7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter((y_test)**2, (y_pred_ridge)**2)\n",
        "plt.xlabel('Actual ')\n",
        "plt.ylabel('Predicted ')"
      ],
      "metadata": {
        "id": "EBpNnZIXBNIt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Resuldual Analysis\n",
        "fig=plt.figure(figsize=(8,8))\n",
        "\n",
        "sns.distplot(((y_test)**2- (y_pred_ridge)**2),bins=20,color='r')\n",
        "\n",
        "#Plot Label\n",
        "fig.suptitle('Residual Analysis', fontsize = 20)"
      ],
      "metadata": {
        "id": "jOw80n_ZBlIr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Heteroscadacity\n",
        "plt.scatter((y_pred_ridge)**2,(y_test)**2-(y_pred_ridge)**2,c='r')\n",
        "plt.xlabel('Predicted selling price')\n",
        "plt.ylabel('residuals')"
      ],
      "metadata": {
        "id": "8ltn8GbzBzOJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Linear regression model from statsmodels.api.**"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = sm.add_constant(X) ## let's add an intercept (beta_0) to our model\n",
        "model = sm.OLS(y, X).fit() ## sm.OLS(output, input)\n",
        "predictions = model.predict(X)"
      ],
      "metadata": {
        "id": "Efgxnk8dcz-H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print out the statistics\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "Ppc2OzRFczq_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we see above result 'wind_speed', \"day\" has P>|t| is greater than 0.05 then we can ignore this one from our independen variable....."
      ],
      "metadata": {
        "id": "V6RScyHzd9jw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From above model we can conclude that below point:\n",
        "\n",
        "* We have positive correlation with Hour . As day rises demand of bike increases till midnight and have minimum at morning 5 am.\n",
        "* Temp, Wind_speed, Visibility,Solar_rad, have a positive correlation . We get more demand with increase in temp , visibility.\n",
        "* Rain, Snow have negative correlation with demand of Bike .\n",
        "* Where as Categorical column have Holiday -Have less demnand\n",
        "and No demand on No_Funct_day."
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Thanks:)"
      ],
      "metadata": {
        "id": "pOoCMQG4qC-B"
      }
    }
  ]
}